{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f7b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "###################################################\n",
    "# Loading datasets\n",
    "##################################################\n",
    "\n",
    "account_df = pd.read_csv('raw_file/account-statement-1-1-2024-12-31-2024.csv', delimiter=';')\n",
    "\n",
    "# remove empty columns\n",
    "if '' in account_df.columns:\n",
    "    account_df = account_df.drop('', axis=1)\n",
    "\n",
    "symbols_df = pd.read_csv('raw_file/symbols.csv', delimiter=';')\n",
    "country_df = pd.read_csv('raw_file/country.csv')\n",
    "\n",
    "# Missing symbols (because they are not in the symbols file) but they are in the account file\n",
    "unique_symbols_in_transactions = set(account_df['Symbol'].unique())\n",
    "unique_symbols_in_lookup = set(symbols_df['symbol'].unique())\n",
    "missing_symbols = unique_symbols_in_transactions - unique_symbols_in_lookup\n",
    "\n",
    "if missing_symbols:\n",
    "    missing_symbols_list = [s for s in missing_symbols if pd.notna(s)]\n",
    "    if missing_symbols_list:\n",
    "        # Remove rows with missing values\n",
    "        account_df = account_df[~account_df['Symbol'].isin(missing_symbols_list)]\n",
    "        \n",
    "        # Update the unique symbols list after filtering\n",
    "        unique_symbols_in_transactions = set(account_df['Symbol'].unique())\n",
    "        missing_symbols = unique_symbols_in_transactions - unique_symbols_in_lookup\n",
    "\n",
    "# Check for dividend transactions (handle both spellings)\n",
    "dividend_variations = ['DIVIDEND', 'DIVIDENT']\n",
    "dividend_transactions = account_df[account_df['TransactionType'].isin(dividend_variations)]\n",
    "\n",
    "\n",
    "###################################################\n",
    "# Part 2: Create Dimension Tables\n",
    "##################################################\n",
    "\n",
    "# Dim_Time -  (Quarter only)\n",
    "\n",
    "account_df['Date'] = pd.to_datetime(account_df['Date'], format='%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "# Extract only quarter\n",
    "account_df['quarter'] = 'Q' + account_df['Date'].dt.quarter.astype(str)\n",
    "\n",
    "# Create unique quarters only\n",
    "unique_quarters = account_df[['quarter']].drop_duplicates()\n",
    "\n",
    "dim_time = unique_quarters.copy()\n",
    "dim_time = dim_time.sort_values(['quarter']).reset_index(drop=True)\n",
    "dim_time['time_id'] = range(1, len(dim_time) + 1)\n",
    "\n",
    "# Keep only the essential columns: time_id, quarter\n",
    "dim_time = dim_time[['time_id', 'quarter']]\n",
    "\n",
    "\n",
    "# Dim_Geography \n",
    "\n",
    "# Country name mapping to handle mismatches between country names in symbols data\n",
    "country_name_mapping = {\n",
    "    'Taiwan': 'Taiwan, Province of China',  # symbols file has 'Taiwan', country file has 'Taiwan, Province of China'\n",
    "    'Turkey': 'Türkiye',  # symbols file has 'Turkey', country file has 'Türkiye'\n",
    "}\n",
    "\n",
    "# Apply country mapping to symbols data\n",
    "symbols_df_mapped = symbols_df.copy()\n",
    "symbols_df_mapped['country_mapped'] = symbols_df_mapped['country'].map(country_name_mapping).fillna(symbols_df_mapped['country'])\n",
    "\n",
    "# Get unique countries (using the mapped names)\n",
    "unique_geography = symbols_df_mapped[['country_mapped']].drop_duplicates()\n",
    "\n",
    "dim_geography = unique_geography.copy()\n",
    "dim_geography.columns = ['country_name']\n",
    "\n",
    "# Remove rows with null values \n",
    "dim_geography = dim_geography.dropna().drop_duplicates().reset_index(drop=True)\n",
    "dim_geography = dim_geography.sort_values(['country_name']).reset_index(drop=True)\n",
    "\n",
    "# Add geography_id\n",
    "dim_geography['geography_id'] = range(1, len(dim_geography) + 1)\n",
    "\n",
    "# Dim_Symbol\n",
    "\n",
    "dim_symbol = symbols_df[['symbol', 'company_name', 'sector', 'industry']].copy()\n",
    "dim_symbol = dim_symbol.sort_values('symbol').reset_index(drop=True)\n",
    "dim_symbol['symbol_id'] = range(1, len(dim_symbol) + 1)\n",
    "\n",
    "# Dim_TransactionType\n",
    "\n",
    "unique_types = sorted(account_df['TransactionType'].unique())\n",
    "dim_transaction_type = pd.DataFrame({\n",
    "    'transaction_type': unique_types,\n",
    "    'transaction_type_id': range(1, len(unique_types) + 1)\n",
    "})\n",
    "\n",
    "###################################################\n",
    "# Part 3: Create Fact Table\n",
    "##################################################\n",
    "\n",
    "fact_transactions = account_df.copy()\n",
    "\n",
    "# Ensure date_only is datetime type for proper merging\n",
    "fact_transactions['quarter_for_merge'] = 'Q' + fact_transactions['Date'].dt.quarter.astype(str)\n",
    "\n",
    "# Add foreign keys\n",
    "# Time dimension - join on quarter\n",
    "fact_transactions = fact_transactions.merge(\n",
    "    dim_time[['quarter', 'time_id']], \n",
    "    left_on='quarter_for_merge', \n",
    "    right_on='quarter', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Symbol dimension\n",
    "fact_transactions = fact_transactions.merge(\n",
    "    dim_symbol[['symbol', 'symbol_id']], \n",
    "    left_on='Symbol', \n",
    "    right_on='symbol', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Geography dimension \n",
    "symbol_geography = symbols_df[['symbol', 'country']].copy()\n",
    "\n",
    "# Apply country mapping\n",
    "symbol_geography['country_mapped'] = symbol_geography['country'].map(country_name_mapping).fillna(symbol_geography['country'])\n",
    "\n",
    "symbol_geography = symbol_geography.merge(\n",
    "    dim_geography[['country_name', 'geography_id']], \n",
    "    left_on='country_mapped', \n",
    "    right_on='country_name', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "fact_transactions = fact_transactions.merge(\n",
    "    symbol_geography[['symbol', 'geography_id']], \n",
    "    on='symbol', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Transaction type dimension\n",
    "fact_transactions = fact_transactions.merge(\n",
    "    dim_transaction_type, \n",
    "    left_on='TransactionType', \n",
    "    right_on='transaction_type', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Final fact table \n",
    "fact_transactions_final = fact_transactions[[\n",
    "    'IDTransaction', 'time_id', 'geography_id', 'symbol_id', \n",
    "    'transaction_type_id'\n",
    "]].copy()\n",
    "fact_transactions_final.columns = [\n",
    "    'transaction_id', 'time_id', 'geography_id', 'symbol_id', \n",
    "    'transaction_type_id'\n",
    "]\n",
    "\n",
    "# Convert data types handle problem to microsft lida\n",
    "fact_transactions_final['transaction_id'] = fact_transactions_final['transaction_id'].astype('int64')\n",
    "fact_transactions_final['time_id'] = fact_transactions_final['time_id'].astype('int32')\n",
    "fact_transactions_final['geography_id'] = fact_transactions_final['geography_id'].astype('int32')\n",
    "fact_transactions_final['symbol_id'] = fact_transactions_final['symbol_id'].astype('int32')\n",
    "fact_transactions_final['transaction_type_id'] = fact_transactions_final['transaction_type_id'].astype('int32')\n",
    "\n",
    "\n",
    "\n",
    "###################################################\n",
    "# Create Merged Dataset for Streamlit\n",
    "##################################################\n",
    "\n",
    "# Create complete merged dataset by joining fact table with all dimensions\n",
    "merged_data = fact_transactions_final.copy()\n",
    "\n",
    "# Join with time dimension\n",
    "merged_data = merged_data.merge(dim_time, on='time_id', how='left')\n",
    "\n",
    "# Join with geography dimension\n",
    "merged_data = merged_data.merge(dim_geography, on='geography_id', how='left')\n",
    "\n",
    "# Join with symbol dimension\n",
    "merged_data = merged_data.merge(dim_symbol, on='symbol_id', how='left')\n",
    "\n",
    "# Join with transaction type dimension\n",
    "merged_data = merged_data.merge(dim_transaction_type, on='transaction_type_id', how='left')\n",
    "\n",
    "# Select only the columns needed for analysis \n",
    "merged_final = merged_data[[\n",
    "    'quarter', 'country_name', 'symbol', 'company_name', \n",
    "    'sector', 'industry', 'transaction_type'\n",
    "]].copy()\n",
    "\n",
    "\n",
    "\n",
    "###################################################\n",
    "# Save data\n",
    "##################################################\n",
    "'''\n",
    "# Save dimension tables (for reference)\n",
    "dim_time.to_csv('dim_time.csv', index=False)\n",
    "dim_geography.to_csv('dim_geography.csv', index=False)\n",
    "dim_symbol.to_csv('dim_symbol.csv', index=False)\n",
    "dim_transaction_type.to_csv('dim_transaction_type.csv', index=False)\n",
    "\n",
    "# Save fact table (for reference)\n",
    "fact_transactions_final.to_csv('fact_transactions.csv', index=False)\n",
    "'''\n",
    "# Save merged dataset for Streamlit \n",
    "merged_final.to_csv('transactions_merged.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
